<!doctype html>
<html lang='en'>

<head>
  <meta charset="UTF-8">
  <title>
    
    Keto | Training
    
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,400;0,500;0,700;1,400;1,700&family=Poppins&display=swap"
    rel="stylesheet">
  <link href=" https://fonts.googleapis.com/css?family=Roboto|Source+Code+Pro" rel="stylesheet">
  <link href="https://ketozhang.github.io/static/prism.css" rel="stylesheet">
  <link href="https://ketozhang.github.io/static/prism-atom-dark.css" rel="stylesheet">

  <!-- CSS Stylesheet -->
  <link href="https://ketozhang.github.io/static/favicon.ico" rel="shortcut icon">
  
  <link href="/static/main.css?89cdc999" rel="stylesheet">
  

  <!-- LaTeX Stylesheet -->
  
  <div class="d-none">
    $$
    \newcommand{d}{\mathrm d}
    \newcommand{avg}[1]{\expval{#1}}
    \renewcommand{vec}[1]{\vectorbold{#1}}
    $$
  </div>
  
</head>

<body>
  
<div class="container-fluid" id="note">
  <!-- <nav class="navbar navbar-expand-lg">
        <button id="sidenavCollapse" class="btn btn-info" type="button">
            <i class="fas fa-align-left"></i>
            <span>Toggle Sidebar</span>
        </button>
    </nav> -->
  <article class="row">
    <!-- Notebook Sidenav -->
    <div class="col-3 bg-light pt-1">
      <div class="sidenav sticky-top vh-80">
        <div class="sidenav-header row no-gutters">
          <div class="col-9">
            <strong>Training</strong>
          </div>
          <div class="col-2 offset-1">
            <a class="go-up" href="https://ketozhang.github.io/notes/Data_Science/Statistical_Modeling/Neural_Networks/" role="button">
              <img src="https://img.icons8.com/dotty/80/000000/up.png" style="width: 25px; height: 25px" />
            </a>
          </div>
        </div>
        <div class="sidenav-body no-gutters">
          <ul class="no-list-style pl-3">
            
          </ul>
        </div>
      </div>
    </div>

    <!-- Content -->
    <div class="col-7 col-md-6">
      <h1 class="title text-center pt-3">Training</h1>
      
      <div class="markdown-content">
        <p>From here on, we will deal with only single layer NN for
simplicity.</p>
<p>The final loss function is given as <span
class="math inline">\(\mathcal L (z,y)\)</span> where <span
class="math inline">\(z = h(X_i)\)</span> and is a vector of size <span
class="math inline">\(k\)</span>. <span
class="math inline">\(h(X_i)\)</span> is treated as <span
class="math inline">\(k\)</span> predictions of the label vector <span
class="math inline">\(y\)</span> hence the loss function actually takes
in <span class="math inline">\(Y \in \mathbb R^{n \times k}\)</span></p>
<p><span class="math display">\[
\mathcal L = \frac{1}{n}\sum_{i=1}^n L(h(X_i), Y_i )
\]</span></p>
<p>With the loss function established we begin the algorithm:</p>
<ol type="1">
<li>Set all weights to random in all transformation matrix <span
class="math inline">\(T^{(\ell)}\)</span>. This also motivates an alias
for <span class="math inline">\(T\)</span> which is the weight matrix
(sometimes written as <span class="math inline">\(V,W\)</span> for
one-layer NN)</li>
<li>Calculate the error <span
class="math inline">\(\varepsilon\)</span></li>
<li>Gradient descent update to the weights.</li>
</ol>
<p>Now the hard part is computing the gradient. Naively one may compute
the gradient for each weight (i.e., each edge) of the NN which would
cost <span class="math inline">\(\Theta(\text{edges})^2\)</span>. The
better idea is to update the edges as it goes through dynamic
programming. Using this idea we get
<strong>backpropagation</strong>.</p>
<h2 id="backpropagation">Backpropagation</h2>
<p>An update rule that cost <span class="math inline">\(\mathcal
O(\text{edges})\)</span> to calculate the gradient. There’s two parts of
back pass which is forward pass and backward propagating.</p>
<p>We simplify the problem by doing stochastic gradient descent on one
sample point. The goal is to solve for,</p>
<p><span class="math display">\[
\nabla_{T^{(\ell)}} L
\]</span></p>
<p>Let’s start with <span class="math inline">\(T^{(1)}\)</span> which
is an input of both <span class="math inline">\(h\)</span> thus also
<span class="math inline">\(z\)</span> since <span
class="math inline">\(L \circ (z, y) \circ (h, T^{(2)}) \circ (x,
T^{(1)})\)</span>.</p>
<p>For each row or node <span class="math inline">\(T_i^{(1)}\)</span>
<span class="math display">\[
\nabla_{T_i^{(1)}}L = \underbrace{\frac{\partial L}{\partial
h_i}}_\text{back pass} \overbrace{\nabla_{T_i^{(1)}} h_i}^\text{foward
pass}
\]</span></p>

      </div>
      
    </div>
    <!-- On This Page -->
    <div class="col-md-3 d-none d-md-block">
      <div class="onthispage sidenav small">
    <div class="sidenav-header">
        <strong>&#9776; On This Page</strong>
    </div>
    <div class="onthispage-collapse">
        <div class="sidenav-body bg-light">
            <ul class="onthispage-list no-list-style"></ul>
        </div>
    </div>
</div>
    </div>
  </article>
</div>


  <!-- Scripts -->
  <script src="https://code.jquery.com/jquery-3.4.1.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>

  <script src="https://ketozhang.github.io/static/js/datetime.js"></script>
  <script src="https://ketozhang.github.io/static/js/disqus.js"></script>
  <script src="https://ketozhang.github.io/static/js/codeHighlight.js"></script>
  <script src="https://ketozhang.github.io/static/js/prism.js"></script>
  <script src="https://ketozhang.github.io/static/js/onthispage.js"></script>
  <script src="https://ketozhang.github.io/static/js/markdown.js"></script>

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://ketozhang.github.io/static/js/mathjax_config.js" defer></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>

  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
    crossorigin="anonymous"></script>


  <!-- Custom Global scripts -->
  <script>
    $(document).ready(function () {
      Prism.highlightAll();
    })
  </script>

  <!-- Local scripts -->
  
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.js"></script>
<script>
  anchors.add();
</script>

</body>

</html>