<p>The most prevalent distribution appearing in countless fields is the Gaussian or normal distribution.</p>
<p><span class="math display">\[X \sim N(\mu, \sigma)\]</span> <span class="math display">\[P(X=x) = \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
<ul>
<li><strong>Properties</strong>
<ul>
<li><p><strong>Standard Normal Distribution</strong></p>
<p>The standard normal distribution is <span class="math inline">\(N(0,1)\)</span> which plays an important role in motivating why we standardize random variables. Say for a Gaussian random variable <span class="math inline">\(X\)</span>,</p>
<p><span class="math display">\[ Y = \frac{X-\mu_X}{\sigma_X} \iff Y \sim N(0,1)\]</span></p></li>
<li><p><strong>Independent Joint Probability (Rotational Invariant)</strong></p>
<p>Due to the distribution's property of rotational invariance, the joint property of two iid Gaussian is a Gaussian however you rotate the random variable axes. Even better the Gaussian has the mean and variance of the sums of the two Gaussians.</p>
<p><span class="math display">\[
P(X,Y) = \text{N}(\mu_X + \mu_Y, \sigma_X^2 + \sigma_Y^2)
\]</span></p></li>
<li><p><strong>Sum:</strong></p>
<p><span class="math display">\[
P(X+Y) =
\]</span></p></li>
<li><p><strong>Characteristics Function</strong>:</p>
<p><span class="math display">\[\tilde p(x) = \exp{\left[-ik\mu -\frac{k^2\sigma^2}{2}\right]} \]</span></p></li>
<li><p><strong>Cumulants and Moments</strong>: <span class="math display">\[
    \avg{x}_c = \mu ,\quad \avg{x^2}_c = \sigma^2,\quad \avg{x^n}_c = 0, \quad \ldots,\quad  \avg{x^n}_c = 0\\
    \avg{x} = \mu ,\quad \avg{x^2} = \sigma^2 + \mu^2,\quad \avg{x^n} = 3\sigma^2\mu + \mu^3, \quad \ldots
\]</span></p></li>
</ul></li>
</ul>
<h2 id="central-limit-theorem">Central Limit Theorem</h2>
<p>For iid random variables $X_1, X_2, $ each with the same mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Let <span class="math inline">\(\bar X\)</span> be the sample mean,</p>
<p><span class="math display">\[ \bar X = \frac{1}{n}\sum_i^n{X_i} \]</span> <span class="math display">\[ \text{Var}[\bar X] = \frac{\sigma^2}{n}\]</span></p>
<p>Let's define the random variable <span class="math inline">\(Z\)</span> to be the standardized sample mean,</p>
<p><span class="math display">\[ Z = \frac{\bar X - \mu}{\frac{\sigma}{\sqrt{n}}} \]</span></p>
<p>As <span class="math inline">\(n \rightarrow \infty\)</span>, this <span class="math inline">\(Z\)</span> tends towards a <span class="math inline">\(N(0,1)\)</span></p>
<p><span class="math display">\[ P(Z \le c) \rightarrow \frac{1}{\sqrt{2\pi}} \int_{-\infty}^c e^{-x^2/2}~\mathrm dx \]</span></p>
<h2 id="multivariate-gaussian">Multivariate Gaussian</h2>
<p>For a vector of random variables <span class="math inline">\(\boldsymbol x\)</span>, the multidimensional or multivariate gaussian is given by</p>
<p><span class="math display">\[
\boldsymbol X \sim \mathcal N(\boldsymbol{\mu}, \Sigma)\\
P(x) = (2 \pi \det \Sigma)^{-1/2}\exp\left[-\frac{1}{2}(\boldsymbol x- \boldsymbol \mu)^T \Sigma^{-1} (\boldsymbol x- \boldsymbol \mu)\right]
\]</span></p>
<ul>
<li><span class="math inline">\(\Sigma\)</span> : The covariance matrix</li>
</ul>
<p>More compact is to treat <span class="math inline">\((\boldsymbol x- \boldsymbol \mu)^T \Sigma^{-1} (\boldsymbol x- \boldsymbol \mu)\)</span> as the squared distance of some vector <span class="math inline">\(\Sigma^{-1/2} \boldsymbol \Delta\)</span> where <span class="math inline">\(\boldsymbol\Delta = \boldsymbol{x} - \boldsymbol{\mu}\)</span> which is known as the <strong>deviation vector</strong>. This compact form is given as,</p>
<p><span class="math display">\[
P(\boldsymbol\Delta) = (2 \pi \det \Sigma)^{-1/2}\exp\left[-\frac{1}{2}\left\lvert\Sigma^{-1/2} \boldsymbol \Delta\right\rvert^2\right]
\]</span></p>
<h3 id="covariance-matrix">Covariance Matrix</h3>
<p>The covariance matrix <span class="math inline">\(\Sigma\)</span> is a semipositive definite (symmetric) matrix</p>
<dl>
<dt>Diagonal Covariance Matrix</dt>
<dd><p>If the covariance matrix is diagonal then</p>
<p><span class="math display">\[ P(\boldsymbol{x}) = \prod{P(X_i)} \]</span></p>
</dd>
</dl>
