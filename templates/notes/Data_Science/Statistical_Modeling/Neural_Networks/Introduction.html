<h2 id="single-hidden-layer">Single Hidden Layer</h2>
<p>Adding a single hidden layer, the math gets quite verbose. It is easier to treat an input to a node as a transformation matrix <span class="math inline">\(T\)</span>. For the single hidden layer NN, there are two transformations <span class="math inline">\(T^{(1)}\)</span> and <span class="math inline">\(T^{(2)}\)</span>.</p>
<p>Let's begin with a single sample <span class="math inline">\(x \in \mathbb R^{d}\)</span>. At every step along the way we will always add the ficticious dimension of value 1 for the intercept. * <span class="math inline">\(T^{(1)}\)</span> takes in <span class="math inline">\(x\)</span> as <span class="math inline">\(d+1\)</span> input nodes and outputs <span class="math inline">\(h \in \mathbb R^{m}\)</span> * <span class="math inline">\(T^{(2)}\)</span> takes in <span class="math inline">\(h\)</span> as <span class="math inline">\(m+1\)</span> nodes and outputs <span class="math inline">\(z \in \mathbb R^{k}\)</span></p>
