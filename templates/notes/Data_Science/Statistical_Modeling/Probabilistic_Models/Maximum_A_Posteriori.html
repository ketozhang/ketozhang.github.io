<h2 id="uniform-prior">Uniform Prior</h2>
<p>Using a uniform prior, the MAP becomes the MLE</p>
<div class="Example">
<p>Suppose we want to find the chance of head <span class="math inline">\(p\)</span> of a possibly unfair coin. However we have no reason to expect the coin to be unfair as most coin tosses are fair-ish. We take the uniform prior.</p>
<p><span class="math display">\[
p  \sim \text{Uniform}(0,1)
\]</span></p>
<p>We perform <span class="math inline">\(n\)</span> trials with the coin and got <span class="math inline">\(H=k\)</span> heads. The likelihood is binomial. The posterior distribution is then,</p>
<p><span class="math display">\[
\begin{align*}
    P(p \mid H = k)  &amp;= \frac{1 \cdot P(H=k \mid p)}{P(H=k)}\\
                     &amp;\propto P(H=k \mid p) \\
    P(p \mid H = k)  &amp;\propto p^{k}(1-p)^{n-k}
\end{align*}
\]</span></p>
<p>Since <span class="math inline">\(p\)</span> is a random variable the posterior distribution is,</p>
<p><span class="math display">\[
(p \mid H=k) \sim \text{Beta}(k+1, n-k+1)
\]</span></p>
<p>With expectation and MAP,</p>
<p><span class="math display">\[
E(p \mid H=k) = \frac{k+1}{n+2}
\]</span></p>
<p><span class="math display">\[
\text{mode} (p \mid H=k) = \frac{k}{n}
\]</span></p>
<p>At large <span class="math inline">\(n\)</span>, these two are nearly equal. We have found that the observed propotion of heads is the MAP.</p>
</div>
<h2 id="disproportionate-prior">Disproportionate Prior</h2>
<p>Suppose you want to determine the chance of an event <span class="math inline">\(p\)</span>. If you believe the event is disproportionate, that is, you believe on average there is <span class="math inline">\(x\)</span> events out of <span class="math inline">\(n\)</span>.</p>
<p><span class="math display">\[
E(p) = \frac{x}{n}
\]</span></p>
<p>In general the proposed <span class="math inline">\(E(p)\)</span> does not have to be a rational number.</p>
<p><span class="math display">\[
p \sim \text{Beta}(x, n-x)
\]</span></p>
<div class="Example">
<p>Using the unfair coin example above, suppose in life, we have experience a lot of cheating so we think that the coin is unfair. Our prior knowledge motivates us to propose the coin lands head at chance <span class="math inline">\(70\%\)</span>,</p>
<p><span class="math display">\[
E(p) = \frac{7}{10}
\]</span></p>
<p>We take the prior distribution to be <span class="math inline">\(p \sim \text{Beta}(7, 3)\)</span>.</p>
</div>
