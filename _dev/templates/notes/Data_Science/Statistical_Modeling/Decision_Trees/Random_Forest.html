<p>To begin talking about random forest we need to cover bagging.</p>
<h2 id="bagging">Bagging</h2>
<p>Bootsrap Aggregating or Bagging is done by training <span class="math inline">\(T\)</span> trees where for each tree it is trained by some dataset <span class="math inline">\(X&#39; \subseteq X\)</span> where <span class="math inline">\(X&#39;\)</span> is generated by sampling <span class="math inline">\(n&#39;\)</span> samples from <span class="math inline">\(X\)</span> with replacement.</p>
<h2 id="random-forest">Random Forest</h2>
<p>Now, random forest takes bagging and add another randomness to the features used by each tree. Here, each tree takes <span class="math inline">\(d&#39; &lt; d\)</span> features randomly sampled without replacement from the features.</p>
<ul>
<li>For classification use <span class="math inline">\(d&#39; \approx \sqrt{d}\)</span>.</li>
<li>For regression use <span class="math inline">\(d&#39; \approx d/3\)</span>.</li>
</ul>
