<p>The exponential decay distribution is a continuous distribution,</p>
<p><span class="math display">\[
f(t) = \lambda e^{-\lambda t}~, \qquad t \ge 0
\]</span></p>
<dl>
<dt>CDF</dt>
<dd><span class="math display">\[
F(t) = 1 - e^{-\lambda t}~
\]</span>
</dd>
<dt>Survival Function</dt>
<dd>The compelement of the CDF is known as the survival function because it is the chance that the event occurs (usually some death) after some time <span class="math inline">\(t\)</span>. <span class="math display">\[
P(T&gt;t) = e^{-\lambda t}
\]</span>
</dd>
<dt>Expectation</dt>
<dd><p>By the tail sum formula, we can use the survival function for the expectation</p>
<p><span class="math display">\[
E(T) = \int_0^\infty P(X &gt; t)~ dt = \int_0^\infty e^{-\lambda t}~ dt = \frac{1}{\lambda}
\]</span></p>
</dd>
<dt>Variance</dt>
<dd><p>Since the second moment is,</p>
<p><span class="math display">\[
E(T^2) = \frac{2}{\lambda}
\]</span></p>
<p>The variance is</p>
<p><span class="math display">\[
\text{Var}(T) = \frac{1}{\lambda^2}
\]</span></p>
</dd>
</dl>
<ul>
<li>Continuous analogy to the geometric distribution.</li>
<li><p><span class="math inline">\(\lambda\)</span> : Interpet as the probability frequency of the event.</p>
<p>You can see this setting <span class="math inline">\(x = 1/\lambda\)</span> then <span class="math inline">\(P(X&gt;x) = 1/e\)</span>. So <span class="math inline">\(1/\lambda\)</span> is the period to decrease the probability that <span class="math inline">\(P(X&gt;x)\)</span> by a factor of <span class="math inline">\(e^{-1}\)</span>.</p></li>
</ul>
<dl>
<dt>Median</dt>
<dd><p>The median of the exponential occurs when</p>
<p><span class="math display">\[
F(t) =  0.5
\]</span></p>
<p>Equivalently when the survival and cdf intersects</p>
<p><span class="math display">\[
P(T &gt; t_{0.5}) = P(T \le t_{0.5})
\]</span></p>
<p>This allows us to simply solve <span class="math inline">\(t\)</span> when letting the survival function go to <span class="math inline">\(50\%\)</span>,</p>
<p><span class="math display">\[
\begin{gather*}
e^{-\lambda t_{0.5}} = 0.5\\
\Big\Downarrow\\
t_{0.5} = \frac{\log(2)}{\lambda} = \log(2)E(T)
\end{gather*}
\]</span></p>
</dd>
<dt>Memoryless Property</dt>
<dd><p>Given an event has occur at <span class="math inline">\(T &gt; t_1\)</span>, the chance that another event occur afterwards <span class="math inline">\(T &gt; t_1 + t_2\)</span> is independent of the first</p>
<p><span class="math display">\[
P(T &gt; t_1 + t_2 \mid T &gt; t_1) = P(T &gt; t_2)
\]</span></p>
<div class="Proof">
<p><span class="math display">\[
\begin{align*}
P(T &gt; t_1 + t_2 \mid T &gt; t_1) &amp;= \frac{P(T &gt; t_1 + t_2, T &gt; t_1)}{P(T &gt; t_t)} \\
&amp;= \frac{P(T &gt; t_1 + t_2)}{P(T &gt; t_t)} \\
&amp;= e^{-\lambda t_2}\\
&amp;= P(T &gt; t_2)
\end{align*}
\]</span></p>
</div>
</dd>
</dl>
<h2 id="relationship-to-poisson-distribution">Relationship to Poisson Distribution</h2>
<p>See <a href="../Discrete_Distributions/Poisson#Poisson_Process">Poisson Process</a>.</p>
